{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPooling2D\n",
    "from keras.layers import Activation,Dropout,Flatten, Dense\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "import tkinter \n",
    "from tkinter import messagebox\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width,img_height=150,150\n",
    "train_data_dir='F:\\Mini Project\\Datasets\\Sugarcane\\Train'\n",
    "validation_data_dir='F:\\Mini Project\\Datasets\\Sugarcane\\Validation'\n",
    "no_training_samples=150\n",
    "no_validation_samples=30\n",
    "epochs=10\n",
    "batch_size=20\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if K.image_data_format()=='channels_first':  \n",
    "    input_shape=(3,img_width, img_height)\n",
    "else:\n",
    "    input_shape=(img_width, img_height, 3)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen=ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 324 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen=ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator=train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width,img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 63 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator=test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width,img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 148, 148, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 74, 74, 32)        0         \n",
      "=================================================================\n",
      "Total params: 896\n",
      "Trainable params: 896\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 148, 148, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 72, 72, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 72, 72, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 82944)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                5308480   \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 5,327,937\n",
      "Trainable params: 5,327,937\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Conv2D(32,(3,3),input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "\n",
    "model.add(Conv2D(64,(3,3),input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "               metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 1.4346 - accuracy: 0.5583"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\YASHWANTH MACHIRAJU\\Anaconda3\\envs\\yashwanth\\lib\\site-packages\\PIL\\Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 3s 491ms/step - loss: 1.3737 - accuracy: 0.5429 - val_loss: 0.7862 - val_accuracy: 0.4500\n",
      "Epoch 2/10\n",
      "7/7 [==============================] - 2s 344ms/step - loss: 0.6654 - accuracy: 0.5403 - val_loss: 1.2487 - val_accuracy: 0.3500\n",
      "Epoch 3/10\n",
      "7/7 [==============================] - 3s 410ms/step - loss: 0.6732 - accuracy: 0.5571 - val_loss: 0.5836 - val_accuracy: 0.6500\n",
      "Epoch 4/10\n",
      "3/7 [===========>..................] - ETA: 1s - loss: 0.5980 - accuracy: 0.5333"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=no_training_samples// batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=no_validation_samples // batch_size)\n",
    "\n",
    "model.save_weights('first_try.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.save('catsanddogs.h5')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    " from keras.models import load_model\n",
    " new_model=load_model('catsanddogs.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's the Sugarcane Crop \n",
      "F:\\Mini Project\\Datasets\\Sugarcane\\Validation\\Sugarcane Weed\\convolvulus arvensis (176).jpg\n",
      "It's the Sugarcane Crop \n",
      "F:\\Mini Project\\Datasets\\Sugarcane\\Validation\\Sugarcane Weed\\convolvulus arvensis (176).jpg\n",
      "It's the Weed\n",
      "F:\\Mini Project\\Datasets\\Sugarcane\\Validation\\Sugarcane Weed\\convolvulus arvensis (177).jpg\n",
      "It's the Weed\n",
      "F:\\Mini Project\\Datasets\\Sugarcane\\Validation\\Sugarcane Weed\\convolvulus arvensis (178).jpg\n",
      "It's the Weed\n",
      "F:\\Mini Project\\Datasets\\Sugarcane\\Validation\\Sugarcane Weed\\convolvulus arvensis (179).jpg\n",
      "It's the Weed\n",
      "F:\\Mini Project\\Datasets\\Sugarcane\\Validation\\Sugarcane Weed\\convolvulus arvensis (180).jpg\n",
      "It's the Sugarcane Crop \n",
      "F:\\Mini Project\\Datasets\\Sugarcane\\Validation\\Sugarcane Weed\\convolvulus arvensis (158).jpg\n",
      "It's the Weed\n",
      "F:\\Mini Project\\Datasets\\Sugarcane\\Validation\\Sugarcane Weed\\convolvulus arvensis (159).jpg\n",
      "It's the Sugarcane Crop \n",
      "F:\\Mini Project\\Datasets\\Sugarcane\\Validation\\Sugarcane Crop\\216.jpg\n",
      "It's the Sugarcane Crop \n",
      "F:\\Mini Project\\Datasets\\Sugarcane\\Validation\\Sugarcane Crop\\217.jpg\n",
      "It's the Sugarcane Crop \n",
      "F:\\Mini Project\\Datasets\\Sugarcane\\Validation\\Sugarcane Crop\\218.jpg\n",
      "It's the Sugarcane Crop \n",
      "F:\\Mini Project\\Datasets\\Sugarcane\\Validation\\Sugarcane Crop\\219.jpg\n",
      "It's the Sugarcane Crop \n",
      "F:\\Mini Project\\Datasets\\Sugarcane\\Validation\\Sugarcane Crop\\220.jpg\n"
     ]
    }
   ],
   "source": [
    "import tkinter \n",
    "from tkinter import messagebox\n",
    "from tkinter import *\n",
    "from PIL import Image\n",
    "from PIL import ImageTk\n",
    "from tkinter import ttk\n",
    "\n",
    "window=tkinter.Tk()\n",
    "window.title(\"Weed Detection Software\")\n",
    "label=tkinter.Label(window,text=\"Welcome to Weed Detection Software\",fg=\"orange\",font=(\"Arial Bold\",30)).pack()\n",
    "label1=tkinter.Label(window,text=\"Please upload your image to verify whether it is the image of a crop or a weed\",fg=\"darkblue\",font=(\"Arial Bold\",15)).pack()\n",
    "window.geometry('800x500')\n",
    "bgImage=PhotoImage(file=\"F:\\\\Mini Project\\\\Background\\\\Background.png\")\n",
    "Label(window,image=bgImage).place(relwidth=1,relheight=1)\n",
    "e=tkinter.Entry(window,width=10)\n",
    "e.place(height=20,width=1000,relx=0.3,rely=0.3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def clickme():\n",
    "    \n",
    "   # label2=tkinter.Label(window,text=hello).pack() \n",
    "    global s\n",
    "    s=e.get()\n",
    "    messagebox.showinfo(\"Upload Success!\",\"Upload successful\")\n",
    "    img_pred=image.load_img(s,target_size=(150,150))\n",
    "    img_pred=image.img_to_array(img_pred)\n",
    "    img_pred=np.expand_dims(img_pred,axis=0)\n",
    "\n",
    "    rslt=model.predict(img_pred)\n",
    "    \n",
    "    if rslt[0][0]==1:\n",
    "        prediction=\"It's the Weed\"\n",
    "    else:\n",
    "        prediction=\"It's the Sugarcane Crop \"\n",
    "    print(prediction)\n",
    "   \n",
    "    messagebox.showinfo(\"Prediction Success!\", prediction)\n",
    "    print(s)\n",
    "    \n",
    "\n",
    "txt=tkinter.Entry(window,width=10)\n",
    "\n",
    "bt=tkinter.Button(window,text=\"Upload!\",bg=\"darkblue\",fg=\"white\",command=clickme)\n",
    "label2=tkinter.Label(window,text=\"Enter the location of file in your system\")\n",
    "label2.place(relx=0,rely=0.3)\n",
    "bt.pack()\n",
    "bt.place(height=20, width=100,relx=0.5,rely=0.5) \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "window.mainloop()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
