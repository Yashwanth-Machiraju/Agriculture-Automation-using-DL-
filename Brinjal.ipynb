{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPooling2D\n",
    "from keras.layers import Activation,Dropout,Flatten, Dense\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "import tkinter \n",
    "from tkinter import messagebox\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width,img_height=150,150\n",
    "train_data_dir='F:\\Mini Project\\Datasets\\Brinjal\\Train'\n",
    "validation_data_dir='F:\\Mini Project\\Datasets\\Brinjal\\Validation'\n",
    "no_training_samples=200\n",
    "no_validation_samples=30\n",
    "epochs=10\n",
    "batch_size=20\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if K.image_data_format()=='channels_first':  \n",
    "    input_shape=(3,img_width, img_height)\n",
    "else:\n",
    "    input_shape=(img_width, img_height, 3)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen=ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 411 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen=ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator=train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width,img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 101 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator=test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width,img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 148, 148, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 74, 74, 32)        0         \n",
      "=================================================================\n",
      "Total params: 896\n",
      "Trainable params: 896\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 148, 148, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 72, 72, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 72, 72, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 36, 36, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 34, 34, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 34, 34, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 17, 17, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 18496)             0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 64)                1183808   \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,212,513\n",
      "Trainable params: 1,212,513\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Conv2D(32,(3,3),input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "\n",
    "model.add(Conv2D(32,(3,3),input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "\n",
    "model.add(Conv2D(64,(3,3),input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "               metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 4s 404ms/step - loss: 0.3424 - accuracy: 0.8650 - val_loss: 0.3133 - val_accuracy: 0.9000\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 4s 372ms/step - loss: 0.2773 - accuracy: 0.8691 - val_loss: 0.3786 - val_accuracy: 0.8000\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 4s 361ms/step - loss: 0.2571 - accuracy: 0.9100 - val_loss: 0.2321 - val_accuracy: 0.9000\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 4s 363ms/step - loss: 0.3195 - accuracy: 0.8534 - val_loss: 0.5890 - val_accuracy: 0.8500\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 4s 387ms/step - loss: 0.2603 - accuracy: 0.9150 - val_loss: 0.8320 - val_accuracy: 0.7000\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 3s 333ms/step - loss: 0.2675 - accuracy: 0.8691 - val_loss: 0.5207 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 4s 396ms/step - loss: 0.2088 - accuracy: 0.9050 - val_loss: 0.4709 - val_accuracy: 0.9000\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 4s 383ms/step - loss: 0.2065 - accuracy: 0.9000 - val_loss: 0.5443 - val_accuracy: 0.8500\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 3s 329ms/step - loss: 0.1994 - accuracy: 0.9267 - val_loss: 0.0904 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 4s 368ms/step - loss: 0.2512 - accuracy: 0.9100 - val_loss: 0.3123 - val_accuracy: 0.8500\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=no_training_samples// batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=no_validation_samples // batch_size)\n",
    "\n",
    "model.save_weights('first_try.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.save('catsanddogs.h5')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    " from keras.models import load_model\n",
    " new_model=load_model('catsanddogs.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's the Weed\n",
      "F:\\Mini Project\\Datasets\\Brinjal\\Validation\\Brinjal Weed\\301.jpg\n",
      "It's the Weed\n",
      "F:\\Mini Project\\Datasets\\Brinjal\\Validation\\Brinjal Weed\\300.jpg\n",
      "It's the Weed\n",
      "F:\\Mini Project\\Datasets\\Brinjal\\Validation\\Brinjal Weed\\299.jpg\n",
      "It's the Weed\n",
      "F:\\Mini Project\\Datasets\\Brinjal\\Validation\\Brinjal Weed\\298.jpg\n",
      "It's the Paddy Crop \n",
      "F:\\Mini Project\\Datasets\\Brinjal\\Validation\\Brinjal Weed\\297.jpg\n",
      "It's the Paddy Crop \n",
      "F:\\Mini Project\\Datasets\\Brinjal\\Validation\\Brinjal Weed\\296.jpg\n",
      "It's the Paddy Crop \n",
      "F:\\Mini Project\\Datasets\\Brinjal\\Validation\\Brinjal Weed\\295.jpg\n",
      "It's the Paddy Crop \n",
      "F:\\Mini Project\\Datasets\\Brinjal\\Validation\\Brinjal Weed\\293.jpg\n",
      "It's the Weed\n",
      "F:\\Mini Project\\Datasets\\Brinjal\\Validation\\Brinjal Weed\\291.jpg\n",
      "It's the Paddy Crop \n",
      "F:\\Mini Project\\Datasets\\Brinjal\\Validation\\Brinjal Weed\\285.jpg\n",
      "It's the Paddy Crop \n",
      "F:\\Mini Project\\Datasets\\Brinjal\\Validation\\Brinjal Weed\\276.jpg\n",
      "It's the Paddy Crop \n",
      "F:\\Mini Project\\Datasets\\Brinjal\\Validation\\Brinjal Weed\\277.jpg\n",
      "It's the Paddy Crop \n",
      "F:\\Mini Project\\Datasets\\Brinjal\\Validation\\Brinjal Weed\\277.jpg\n",
      "It's the Weed\n",
      "F:\\Mini Project\\Datasets\\Brinjal\\Validation\\Brinjal Weed\\278.jpg\n",
      "It's the Paddy Crop \n",
      "F:\\Mini Project\\Datasets\\Brinjal\\Validation\\Brinjal Weed\\279.jpg\n",
      "It's the Paddy Crop \n",
      "F:\\Mini Project\\Datasets\\Brinjal\\Validation\\Brinjal Weed\\245.jpg\n",
      "It's the Paddy Crop \n",
      "F:\\Mini Project\\Datasets\\Brinjal\\Validation\\Brinjal Weed\\246.jpg\n",
      "It's the Weed\n",
      "F:\\Mini Project\\Datasets\\Brinjal\\Validation\\Brinjal Weed\\247.jpg\n",
      "It's the Weed\n",
      "F:\\Mini Project\\Datasets\\Brinjal\\Validation\\Brinjal Weed\\248.jpg\n",
      "It's the Paddy Crop \n",
      "F:\\Mini Project\\Datasets\\Brinjal\\Validation\\Brinjal Weed\\249.jpg\n",
      "It's the Weed\n",
      "F:\\Mini Project\\Datasets\\Brinjal\\Validation\\Brinjal Weed\\250.jpg\n",
      "It's the Paddy Crop \n",
      "F:\\Mini Project\\Datasets\\Brinjal\\Validation\\Brinjal Weed\\251.jpg\n",
      "It's the Paddy Crop \n",
      "F:\\Mini Project\\Datasets\\Brinjal\\Validation\\Brinjal Weed\\252.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\YASHWANTH MACHIRAJU\\Anaconda3\\envs\\yashwanth\\lib\\tkinter\\__init__.py\", line 1705, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"<ipython-input-11-4ec62059fc23>\", line 28, in clickme\n",
      "    img_pred=image.load_img(s,target_size=(150,150))\n",
      "  File \"C:\\Users\\YASHWANTH MACHIRAJU\\Anaconda3\\envs\\yashwanth\\lib\\site-packages\\keras_preprocessing\\image\\utils.py\", line 110, in load_img\n",
      "    img = pil_image.open(path)\n",
      "  File \"C:\\Users\\YASHWANTH MACHIRAJU\\Anaconda3\\envs\\yashwanth\\lib\\site-packages\\PIL\\Image.py\", line 2809, in open\n",
      "    fp = builtins.open(filename, \"rb\")\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'F:\\\\Mini Project\\\\Datasets\\\\Brinjal\\\\Validation\\\\Brinjal Crop\\\\252.jpg'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's the Paddy Crop \n",
      "F:\\Mini Project\\Datasets\\Brinjal\\Validation\\Brinjal Crop\\204.jpg\n",
      "It's the Paddy Crop \n",
      "F:\\Mini Project\\Datasets\\Brinjal\\Validation\\Brinjal Crop\\205.jpg\n",
      "It's the Paddy Crop \n",
      "F:\\Mini Project\\Datasets\\Brinjal\\Validation\\Brinjal Crop\\206.jpg\n",
      "It's the Paddy Crop \n",
      "F:\\Mini Project\\Datasets\\Brinjal\\Validation\\Brinjal Crop\\207.jpg\n",
      "It's the Paddy Crop \n",
      "F:\\Mini Project\\Datasets\\Brinjal\\Validation\\Brinjal Crop\\208.jpg\n",
      "It's the Weed\n",
      "F:\\Mini Project\\Datasets\\Brinjal\\Validation\\Brinjal Crop\\209.jpg\n"
     ]
    }
   ],
   "source": [
    "import tkinter \n",
    "from tkinter import messagebox\n",
    "from tkinter import *\n",
    "from PIL import Image\n",
    "from PIL import ImageTk\n",
    "from tkinter import ttk\n",
    "\n",
    "window=tkinter.Tk()\n",
    "window.title(\"Weed Detection Software\")\n",
    "label=tkinter.Label(window,text=\"Welcome to Weed Detection Software\",fg=\"orange\",font=(\"Arial Bold\",30)).pack()\n",
    "label1=tkinter.Label(window,text=\"Please upload your image to verify whether it is the image of a crop or a weed\",fg=\"darkblue\",font=(\"Arial Bold\",15)).pack()\n",
    "window.geometry('800x500')\n",
    "bgImage=PhotoImage(file=\"F:\\\\Mini Project\\\\Background\\\\Background.png\")\n",
    "Label(window,image=bgImage).place(relwidth=1,relheight=1)\n",
    "e=tkinter.Entry(window,width=10)\n",
    "e.place(height=20,width=1000,relx=0.3,rely=0.3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def clickme():\n",
    "    \n",
    "   # label2=tkinter.Label(window,text=hello).pack() \n",
    "    global s\n",
    "    s=e.get()\n",
    "    messagebox.showinfo(\"Upload Success!\",\"Upload successful\")\n",
    "    img_pred=image.load_img(s,target_size=(150,150))\n",
    "    img_pred=image.img_to_array(img_pred)\n",
    "    img_pred=np.expand_dims(img_pred,axis=0)\n",
    "\n",
    "    rslt=model.predict(img_pred)\n",
    "    \n",
    "    if rslt[0][0]==1:\n",
    "        prediction=\"It's the Weed\"\n",
    "    else:\n",
    "        prediction=\"It's the Brinjal Crop \"\n",
    "    print(prediction)\n",
    "   \n",
    "    messagebox.showinfo(\"Prediction Success!\", prediction)\n",
    "    print(s)\n",
    "    \n",
    "\n",
    "txt=tkinter.Entry(window,width=10)\n",
    "\n",
    "bt=tkinter.Button(window,text=\"Upload!\",bg=\"darkblue\",fg=\"white\",command=clickme)\n",
    "label2=tkinter.Label(window,text=\"Enter the location of file in your system\")\n",
    "label2.place(relx=0,rely=0.3)\n",
    "bt.pack()\n",
    "bt.place(height=20, width=100,relx=0.5,rely=0.5) \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "window.mainloop()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
