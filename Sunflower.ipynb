{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPooling2D\n",
    "from keras.layers import Activation,Dropout,Flatten, Dense\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "import tkinter \n",
    "from tkinter import messagebox\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width,img_height=150,150\n",
    "train_data_dir='F:\\Mini Project\\Datasets\\Sunflower\\Train'\n",
    "validation_data_dir='F:\\Mini Project\\Datasets\\Sunflower\\Validation'\n",
    "no_training_samples=150\n",
    "no_validation_samples=30\n",
    "epochs=9\n",
    "batch_size=20\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if K.image_data_format()=='channels_first':  \n",
    "    input_shape=(3,img_width, img_height)\n",
    "else:\n",
    "    input_shape=(img_width, img_height, 3)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen=ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 327 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen=ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator=train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width,img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 60 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator=test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width,img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 148, 148, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 74, 74, 32)        0         \n",
      "=================================================================\n",
      "Total params: 896\n",
      "Trainable params: 896\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 148, 148, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 72, 72, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 72, 72, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 36, 36, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 41472)             0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 64)                2654272   \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 2,668,641\n",
      "Trainable params: 2,668,641\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Conv2D(32,(3,3),input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "\n",
    "model.add(Conv2D(32,(3,3),input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "               metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/9\n",
      "7/7 [==============================] - 4s 622ms/step - loss: 0.3731 - accuracy: 0.8857 - val_loss: 0.4346 - val_accuracy: 0.8000\n",
      "Epoch 2/9\n",
      "7/7 [==============================] - 3s 458ms/step - loss: 0.2939 - accuracy: 0.8929 - val_loss: 0.4372 - val_accuracy: 0.9500\n",
      "Epoch 3/9\n",
      "7/7 [==============================] - 2s 289ms/step - loss: 0.2676 - accuracy: 0.9211 - val_loss: 0.2067 - val_accuracy: 0.9000\n",
      "Epoch 4/9\n",
      "7/7 [==============================] - 3s 401ms/step - loss: 0.2565 - accuracy: 0.8929 - val_loss: 0.2380 - val_accuracy: 0.9500\n",
      "Epoch 5/9\n",
      "7/7 [==============================] - 2s 356ms/step - loss: 0.3185 - accuracy: 0.8643 - val_loss: 0.1691 - val_accuracy: 0.9500\n",
      "Epoch 6/9\n",
      "7/7 [==============================] - 3s 366ms/step - loss: 0.2378 - accuracy: 0.9286 - val_loss: 0.1546 - val_accuracy: 0.9500\n",
      "Epoch 7/9\n",
      "7/7 [==============================] - 2s 333ms/step - loss: 0.2334 - accuracy: 0.9134 - val_loss: 0.2113 - val_accuracy: 0.9000\n",
      "Epoch 8/9\n",
      "7/7 [==============================] - 3s 379ms/step - loss: 0.1657 - accuracy: 0.9500 - val_loss: 0.1626 - val_accuracy: 0.9500\n",
      "Epoch 9/9\n",
      "7/7 [==============================] - 3s 380ms/step - loss: 0.2486 - accuracy: 0.9213 - val_loss: 0.3981 - val_accuracy: 0.9000\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=no_training_samples// batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=no_validation_samples // batch_size)\n",
    "\n",
    "model.save_weights('first_try.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.save('catsanddogs.h5')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-c77b5ee9f699>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m211\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mpyplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import make_circles\n",
    "\n",
    "from matplotlib import pyplot\n",
    "pyplot.subplot(211)\n",
    "pyplot.title('Loss')\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "# plot accuracy during training\n",
    "pyplot.subplot(212)\n",
    "pyplot.title('Accuracy')\n",
    "pyplot.plot(history.history['accuracy'], label='train')\n",
    "pyplot.plot(history.history['val_accuracy'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    " from keras.models import load_model\n",
    " new_model=load_model('catsanddogs.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'PIL'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-244158ae3030>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtkinter\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmessagebox\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtkinter\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImageTk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtkinter\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mttk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'PIL'"
     ]
    }
   ],
   "source": [
    "import tkinter \n",
    "from tkinter import messagebox\n",
    "from tkinter import *\n",
    "from PIL import Image\n",
    "from PIL import ImageTk\n",
    "from tkinter import ttk\n",
    "\n",
    "window=tkinter.Tk()\n",
    "window.title(\"Weed Detection Software\")\n",
    "\n",
    "window.geometry('800x500')\n",
    "bgImage=PhotoImage(file=\"F:\\\\Mini Project\\\\Background\\\\Background.png\")\n",
    "Label(window,image=bgImage).place(relwidth=1,relheight=1)\n",
    "e=tkinter.Entry(window,width=10)\n",
    "e.place(height=20,width=1000,relx=0.3,rely=0.3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def clickme():\n",
    "    \n",
    "   # label2=tkinter.Label(window,text=hello).pack() \n",
    "    global s\n",
    "    s=e.get()\n",
    "    messagebox.showinfo(\"Upload Success!\",\"Upload successful\")\n",
    "    img_pred=image.load_img(s,target_size=(150,150))\n",
    "    img_pred=image.img_to_array(img_pred)\n",
    "    img_pred=np.expand_dims(img_pred,axis=0)\n",
    "\n",
    "    rslt=model.predict(img_pred)\n",
    "    \n",
    "    if rslt[0][0]==1:\n",
    "        prediction=\"It's the Weed\"\n",
    "    else:\n",
    "        prediction=\"It's the Sunflower Crop \"\n",
    "    print(prediction)\n",
    "   \n",
    "    messagebox.showinfo(\"Prediction Success!\", prediction)\n",
    "    print(s)\n",
    "    \n",
    "\n",
    "txt=tkinter.Entry(window,width=10)\n",
    "\n",
    "bt=tkinter.Button(window,text=\"Upload!\",bg=\"darkblue\",fg=\"white\",command=clickme)\n",
    "label2=tkinter.Label(window,text=\"Enter the location of file in your system\")\n",
    "label2.place(relx=0,rely=0.3)\n",
    "bt.pack()\n",
    "bt.place(height=20, width=100,relx=0.5,rely=0.5) \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "window.mainloop()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
